#version 460
#extension GL_GOOGLE_include_directive : require
#extension GL_EXT_nonuniform_qualifier : require

#include "Platform.glsl"
#include "common/Material.glsl"
#include "common/UniformBufferObject.glsl"
#include "common/Random.glsl"

layout(binding = 0, rg32ui) uniform uimage2D MiniGBuffer;
layout(binding = 1, rgba8) uniform image2D OutImage;
layout(binding = 2) readonly uniform UniformBufferObjectStruct { UniformBufferObject Camera; };

layout(binding = 4) readonly buffer VertexArray { float Vertices[]; };
layout(binding = 5) readonly buffer IndexArray { uint Indices[]; };
layout(binding = 6) readonly buffer MaterialArray { Material[] Materials; };
layout(binding = 7) readonly buffer OffsetArray { uvec2[] Offsets; };
layout(binding = 8) readonly buffer NodeProxyArray { NodeProxy[] NodeProxies; };
layout(binding = 9, rg16f) uniform image2D OutMotionVector;
layout(binding = 10) buffer AmbientCubeArray { AmbientCube[] Cubes; };
layout(binding = 11) readonly buffer HDRSHArray { SphericalHarmonics[] HDRSHs; };

layout(binding = 12) uniform usampler2D ShadowMapSampler;

layout(set = 1, binding = 0) uniform sampler2D TextureSamplers[];

#include "common/Vertex.glsl"
#include "common/ColorFunc.glsl"
#include "common/AmbientCube.glsl"

#if DESKTOP
layout(local_size_x = 8, local_size_y = 4, local_size_z = 1) in;
#else
layout(local_size_x = 32, local_size_y = 32, local_size_z = 1) in;
#endif

#include "common/VertexFunc.glsl"
#include "common/SampleIBL.glsl"
// 在现有的traceInScreenSpace基础上，添加一个可以获取反弹表面材质的版本
bool traceInScreenSpace(vec3 position, vec3 rayDir, float maxDistance, out vec3 outPosition, out vec3 outNormal, out uint outMaterialIdx) {
    // 屏幕空间步进参数
    const int maxSteps = 10;
    float stepSize = maxDistance / float(maxSteps);
    vec2 texelSize = 1.0 / vec2(imageSize(MiniGBuffer));

    // 起始点
    vec3 rayStart = position + rayDir * 0.1;

    // 追踪光线
    for (int i = 0; i < maxSteps; i++) {
        // 移动光线
        vec3 currentPos = rayStart + rayDir * (i * stepSize);

        // 将当前位置转到屏幕空间
        vec4 currentPosProj = Camera.ViewProjection * vec4(currentPos, 1.0);
        currentPosProj.xyz /= currentPosProj.w;
        vec2 currentUV = currentPosProj.xy * 0.5 + 0.5;

        // 检查是否超出屏幕
        if (any(lessThan(currentUV, vec2(0.0))) || any(greaterThan(currentUV, vec2(1.0))))
        continue;

        // 采样深度
        ivec2 sampleCoord = ivec2(currentUV * vec2(imageSize(MiniGBuffer)));
        uvec2 vBufferSample = imageLoad(MiniGBuffer, sampleCoord).rg;

        // 如果没有命中物体，继续
        if (vBufferSample.r == 0)
        continue;

        // 重建世界空间位置
        vec4 origin = Camera.ModelViewInverse * vec4(0, 0, 0, 1);
        vec4 target = Camera.ProjectionInverse * (vec4(currentPosProj.x, currentPosProj.y, 1, 1));
        vec4 dir = Camera.ModelViewInverse * vec4(normalize(target.xyz), 0);

        vec3 ray_dir = normalize(dir.xyz);

        Vertex sampleVertex = get_material_data(sampleCoord, vBufferSample, origin.xyz, ray_dir);

        // 正确的深度比较方法
        // 将当前世界空间位置投影到屏幕空间
        vec4 currentPosScreenSpace = Camera.ViewProjection * vec4(currentPos, 1.0);
        currentPosScreenSpace.xyz /= currentPosScreenSpace.w;
        float currentDepth = currentPosScreenSpace.z * 0.5 + 0.5; // 转换到[0,1]范围

        // 获取场景中该点的屏幕空间深度
        vec4 samplePosScreenSpace = Camera.ViewProjection * vec4(sampleVertex.Position, 1.0);
        samplePosScreenSpace.xyz /= samplePosScreenSpace.w;
        float sampleDepth = samplePosScreenSpace.z * 0.5 + 0.5; // 转换到[0,1]范围

        // 比较深度值
        float depthTolerance = 0.000001; // 屏幕空间深度的容差应该更小
        if (currentDepth > sampleDepth && currentDepth < sampleDepth + depthTolerance) {
            // 发现阻挡（光线在穿过场景点之前被遮挡）
            outPosition = currentPos;
            outNormal = normalize(sampleVertex.Normal.rgb);

            // 获取材质ID
            NodeProxy hitNode = NodeProxies[vBufferSample.x - 1];
            outMaterialIdx = hitNode.matId[sampleVertex.MaterialIndex];

            return true;
        }
    }

    // 没有发现阻挡
    return false;
}

// 使用屏幕空间近场反弹光照计算
bool calculateSSInterreflection(vec3 position, vec3 rayDir, vec3 normal, uint sourceMaterialIdx, ivec2 ipos, uvec4 RandomSeed, out vec4 reflectionColor) {
    vec3 hitPosition, hitNormal;
    uint hitMaterialIdx;
    reflectionColor = vec4(0);

    // 偏移起始位置，避免自相交
    vec3 offsetPos = position + normal * 0.01;

    // 在屏幕空间中查找反弹点
    if (traceInScreenSpace(offsetPos, rayDir, 2.0, hitPosition, hitNormal, hitMaterialIdx)) {
        // 获取反弹点的材质
        Material hitMaterial = Materials[hitMaterialIdx];

        // 计算反弹点的基础颜色
        vec4 hitAlbedo = hitMaterial.Diffuse;

        // 如果有纹理，采样纹理颜色
//        if (hitMaterial.DiffuseTextureId >= 0) {
//            // 需要计算反弹点的UV坐标，这里使用一个近似值
//            // 实际情况中可能需要更复杂的计算
//            vec2 hitUV = vec2(0.5); // 简化处理，实际应从trace结果中计算
//            vec4 tex = texture(TextureSamplers[hitMaterial.DiffuseTextureId], hitUV);
//            hitAlbedo *= tex * tex;
//        }

        // 计算从光源到反弹点的阴影
        //float hitShadow = getShadow(hitPosition, vec3(0), hitNormal, ipos);

        // 计算反弹点接收到的直接光照
        //vec3 lightVector = normalize(Camera.SunDirection.xyz);
        //float NdotL = max(dot(lightVector, hitNormal), 0.0);
        //vec4 directLight = Camera.SunColor * NdotL * 0.2 * hitShadow;

        // 计算反弹点的环境光照
        vec4 hitAmbient = interpolateIIProbes((hitPosition - CUBE_OFFSET) / CUBE_UNIT, hitNormal) * 2.0f;

        // 组合反弹点的光照结果
        reflectionColor = hitAlbedo * hitAmbient;

        // 根据材质的反射特性和入射角度，调整反射光强度
        //float fresnel = Schlick(max(dot(-rayDir, normal), 0.0), 1.5);
        //float reflectionStrength = mix(0.04, 1.0, fresnel);

        // 考虑材质的金属度和粗糙度
        //Material sourceMaterial = Materials[sourceMaterialIdx];
        //reflectionStrength *= mix(0.5, 1.0, sourceMaterial.Metalness);
        //reflectionStrength *= (1.0 - sourceMaterial.Roughness);

        //reflectionColor *= reflectionStrength;
        return true;
    }
    return false;
}

float getShadow(vec3 worldPos, vec3 jit, vec3 normal, ivec2 ipos) {
    // 计算光源空间坐标
    vec4 posInLightMap = Camera.SunViewProjection * vec4(worldPos + jit * 4.0f, 1.0f);

    // 将光源空间坐标转换到NDC空间 [-1,1] 再转到 [0,1] 的纹理空间
    vec3 projCoords = posInLightMap.xyz / posInLightMap.w;
    projCoords = projCoords * 0.5 + 0.5;
    projCoords.y = 1.0 - projCoords.y;

    float currentDepth = projCoords.z;

    // 基础偏移值
    float bias = 0.0005;

    // 根据法线与光照方向的夹角调整偏移值
    float cosTheta = max(dot(normal, normalize(Camera.SunDirection.xyz)), 0.0);
    bias = mix(0.0005, 0.0002, cosTheta); // 斜面使用更大的偏移值

    // 从阴影贴图中采样获取最近深度
    float closestDepth = unpackHalf2x16(texture(ShadowMapSampler, projCoords.xy).x).x;
    float shadow = currentDepth - bias > closestDepth ? 0.0 : 1.0;

    // 在主阴影通过的情况下进行屏幕空间接触阴影检测
    if (shadow > 0.01) {
        vec3 outPosition;
        vec3 outNormal;
        uint outMaterialIdx;
        float contactShadow = traceInScreenSpace(worldPos + jit, normalize(Camera.SunDirection.xyz), 2.0, outPosition, outNormal, outMaterialIdx) ? 0.0 : 1.0;
        shadow = min(shadow, contactShadow); // 结合两种阴影结果
    }

    return shadow;
}

void main() {

    // checker box
    int adder = Camera.TotalFrames % 2 == 0 ? 1 : 0;
    
    ivec2 ipos = ivec2(gl_GlobalInvocationID.xy);
    uvec4 RandomSeed = InitRandomSeed(ipos.x, ipos.y, Camera.TotalFrames);
    
	ivec2 size = imageSize(MiniGBuffer);
    uvec2 vBuffer = imageLoad(MiniGBuffer, ipos).rg;
    vec2 uv = vec2(ipos) / vec2(size) * 2.0 - 1.0;
    vec4 origin = Camera.ModelViewInverse * vec4(0, 0, 0, 1);
	vec4 target = Camera.ProjectionInverse * (vec4(uv.x, uv.y, 1, 1));
	vec4 dir = Camera.ModelViewInverse * vec4(normalize(target.xyz), 0);
	
	vec3 ray_dir = normalize(dir.xyz);


    Vertex v = get_material_data(ipos, vBuffer, origin.xyz, ray_dir);

    vec3 normal = normalize( v.Normal.rgb);
    vec3 tangent = normalize( v.Tangent.rgb);
    vec3 bitangent = cross(normal, tangent);
    
    NodeProxy node = NodeProxies[vBuffer.x - 1];
    uint materialIndex = 0;
    // here if direct address with node.matId[v.MaterialIndex] will too slow on android
    switch (v.MaterialIndex) {
        case 0:
            materialIndex = node.matId[0];
            break;
        case 1:
            materialIndex = node.matId[1];
            break;
        case 2:
            materialIndex = node.matId[2];
            break;
        case 3:
            materialIndex = node.matId[3];
            break;
        case 4:
            materialIndex = node.matId[4];
            break;
        case 5:
            materialIndex = node.matId[5];
            break;
        case 6:
            materialIndex = node.matId[6];
            break;
        case 7:
            materialIndex = node.matId[7];
            break;
        case 8:
            materialIndex = node.matId[8];
            break;
        case 9:
            materialIndex = node.matId[9];
            break;
        case 10:
            materialIndex = node.matId[10];
            break;
        case 11:
            materialIndex = node.matId[11];
            break;
        case 12:
            materialIndex = node.matId[12];
            break;
        case 13:
            materialIndex = node.matId[13];
            break;
        case 14:
            materialIndex = node.matId[14];
            break;
        case 15:
            materialIndex = node.matId[15];
            break;
    }
    
    Material mat = Materials[materialIndex];
        
    vec4 albedo = mat.Diffuse;
    
    if (mat.DiffuseTextureId >= 0)
    {
        vec4 tex = texture(TextureSamplers[mat.DiffuseTextureId], v.TexCoord);
        albedo *= tex * tex;
    }
    
	// ibl
	const float dotValue = dot(ray_dir, normal);
	const vec3 outwardNormal = dotValue > 0 ? -normal : normal;
	const float cosine = dotValue > 0 ? mat.RefractionIndex * dotValue : -dotValue;
	const float reflectProb = Schlick(cosine, mat.RefractionIndex);
	const float metalProb = mat.Metalness;
    	
	const vec3 lightVector = Camera.SunDirection.xyz;
    const vec4 d = Camera.SunColor * max(dot(lightVector, normalize(v.Normal.rgb)), 0.0) * 0.2f;
    
    vec4 indirectColor = vec4(0);

    float shadow = 0.0f;
    const int jitcount = 8;
    const float range = 0.08f;
    for(int i = 0; i < jitcount; i++) {
        
        // 这里用traceInScreenSpace在屏幕空间trace，如果射到了物件，在采样interpolate反弹，来做近场反弹，如果没有trace结果，再fallback
        //vec3 reflectDir = reflect(ray_dir, normal);
        vec3 reflectDir = AlignWithNormal( RandomInHemiSphere1(RandomSeed), normal );
        vec4 reflectionColor;
        if( calculateSSInterreflection(v.Position, reflectDir, normal, materialIndex, ipos, RandomSeed, reflectionColor) )
        {
            indirectColor += reflectionColor;
        }
        else
        {
            // 没命中，说明可能接受到了天光，直接采样skyprobes，还可以考虑远场遮蔽
            indirectColor += interpolateSkyProbes((v.Position - CUBE_OFFSET) / CUBE_UNIT, normal);
        }
        vec2 jitter2D = (RandomFloat2(RandomSeed) - vec2(0.5f)) * range;
        vec3 jit = tangent * jitter2D.x + bitangent * jitter2D.y;
        shadow += getShadow(v.Position, jit, normal, ipos);
    }
    shadow /= float(jitcount);
    indirectColor /= float(jitcount);

    vec4 outColor = albedo * vec4(indirectColor.rgb,1);
    outColor += albedo * d * shadow;
    
    if(Camera.HDR)
    {
        imageStore(OutImage, ipos, vec4( LinearToST2084UE( outColor.rgb * Camera.PaperWhiteNit / 230.0), 1.0));
    }
    else
    {
        imageStore(OutImage, ipos, vec4( Uncharted2_Tonemapping( outColor.rgb * Camera.PaperWhiteNit / 20000.0), 1.0));
    }

    //imageStore(OutImage, ipos, vec4(closestDepth));
}