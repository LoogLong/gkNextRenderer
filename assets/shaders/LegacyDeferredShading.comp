#version 460
#extension GL_GOOGLE_include_directive : require
#extension GL_EXT_nonuniform_qualifier : require

#include "Platform.glsl"
#include "common/Material.glsl"
#include "common/UniformBufferObject.glsl"
#include "common/ColorFunc.glsl"
#include "common/Random.glsl"

layout(binding = 0, rgba8) readonly uniform image2D GBuffer0Image;
layout(binding = 1, rgba16f) readonly uniform image2D GBuffer1Image;
layout(binding = 2, rgba16f) readonly uniform image2D GBuffer2Image;
layout(binding = 3, rgba8) writeonly uniform image2D OutImage;
layout(binding = 4) readonly uniform UniformBufferObjectStruct { UniformBufferObject Camera; };
layout(binding = 5) buffer AmbientCubeArray { AmbientCube[] Cubes; };
layout(binding = 6) buffer FarAmbientCubeArray { AmbientCube[] FarCubes; };
layout(binding = 7) readonly buffer HDRSHArray { SphericalHarmonics[] HDRSHs; };
layout(binding = 8) uniform sampler2D ShadowMapSampler;

layout(set = 1, binding = 0) uniform sampler2D TextureSamplers[];

#include "common/AmbientCube.glsl"
#include "common/SampleIBL.glsl"

#if DESKTOP
layout(local_size_x = 8, local_size_y = 4, local_size_z = 1) in;
#else
layout(local_size_x = 32, local_size_y = 32, local_size_z = 1) in;
#endif


float getShadow(vec3 worldPos, vec3 jit, vec3 normal, ivec2 ipos) {
    // 计算光源空间坐标
    vec4 posInLightMap = Camera.SunViewProjection * vec4(worldPos + jit * 4.0f, 1.0f);

    // 将光源空间坐标转换到NDC空间 [-1,1] 再转到 [0,1] 的纹理空间
    vec3 projCoords = posInLightMap.xyz / posInLightMap.w;
    projCoords = projCoords * 0.5 + 0.5;
    projCoords.y = 1.0 - projCoords.y;

    float currentDepth = projCoords.z;

    float bias = 0.0005;
    
    float cosTheta = max(dot(normal, normalize(Camera.SunDirection.xyz)), 0.0);
    bias = mix(0.00001, 0.000005, cosTheta);
    
    float closestDepth = texture(ShadowMapSampler, projCoords.xy).x;
    float shadow = currentDepth - bias > closestDepth ? 0.0 : 1.0;

    return shadow;
}

void main() {

    // checker box
    int adder = Camera.TotalFrames % 2 == 0 ? 1 : 0;
    
    ivec2 ipos = ivec2(gl_GlobalInvocationID.xy);
    if(Camera.UseCheckerBoard)
    {
        ipos = ipos * ivec2(2,1);
        if((gl_GlobalInvocationID.y + adder) % 2 == 0) {
            ipos.x += 1;
        }
    }
    
    uvec4 RandomSeed = InitRandomSeed(ipos.x, ipos.y, Camera.TotalFrames);
    
    vec4 albedo = imageLoad(GBuffer0Image, ipos);
    vec4 normalraw = imageLoad(GBuffer1Image, ipos);
    vec4 pbr_param = imageLoad(GBuffer2Image, ipos);
    
    vec3 normal = normalize(normalraw.rgb);

    const float t = 0.5*(normal.y + 1);
    //vec3 iblLight = Camera.HasSky ? SampleIBL(Camera.SkyIdx, normal, Camera.SkyRotation, 1).rgb * Camera.SkyIntensity : vec3(0.0);
    vec4 iblLight = interpolateSkyProbes((pbr_param.xyz - CUBE_OFFSET) / CUBE_UNIT, normal) * 2.0f;
    
    const vec3 lightVector = Camera.SunDirection.xyz;
    const vec4 d = Camera.SunColor * max(dot(lightVector, normal), 0.0) * M_1_PI;

    float shadow = 0.0f;
    if(Camera.HasSun)
    {
        vec3 jit = vec3(0);
        shadow += getShadow(pbr_param.xyz, jit, normal, ipos);
    }

    if( Camera.DebugDraw_Lighting )
    {
        albedo = vec4(0.5,0.5,0.5,1);
    }
    
    vec4 outColor = albedo * d * shadow + iblLight * albedo;

    
    
    if(Camera.HDR)
    {
        imageStore(OutImage, ipos, vec4( LinearToST2084UE( outColor.rgb * Camera.PaperWhiteNit / 230.0), 1.0));
    }
    else
    {
        imageStore(OutImage, ipos , vec4( Uncharted2_Tonemapping( outColor.rgb * Camera.PaperWhiteNit / 20000.0), 1.0));
    }
}